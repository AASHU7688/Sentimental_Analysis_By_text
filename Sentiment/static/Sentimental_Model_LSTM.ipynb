{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import save_model"
      ],
      "metadata": {
        "id": "4cNOojGoN4lP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUXu_tfVN99U",
        "outputId": "ef0616e4-7f89-4276-cfbb-5eb5f82ef04f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/YoutubeCommentsDataSet.csv')  # Adjust file name\n",
        "print(\"Dataset sample:\")\n",
        "print(df.head())\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['Sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiCDdw4BN_sK",
        "outputId": "2e38323e-3dae-4c33-c189-1bd672220a96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sample:\n",
            "                                             Comment Sentiment\n",
            "0  lets not forget that apple pay in 2014 require...   neutral\n",
            "1  here in nz 50 of retailers don’t even have con...  negative\n",
            "2  i will forever acknowledge this channel with t...  positive\n",
            "3  whenever i go to a place that doesn’t take app...  negative\n",
            "4  apple pay is so convenient secure and easy to ...  positive\n",
            "\n",
            "Class distribution:\n",
            "Sentiment\n",
            "positive    11432\n",
            "neutral      4638\n",
            "negative     2338\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Preprocess Text\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['clean_comment'] = df['Comment'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "jNnI0xSzOUH5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Map Sentiments to Numeric Labels\n",
        "label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "df = df[df['Sentiment'].isin(label_map)]\n",
        "df['label'] = df['Sentiment'].map(label_map)"
      ],
      "metadata": {
        "id": "-B4yv8iaOe23"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train–Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_comment'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        ")"
      ],
      "metadata": {
        "id": "yOkZGiECOqVy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Tokenize & Pad Sequences\n",
        "max_words = 10000\n",
        "max_len = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "y_test_cat = to_categorical(y_test, num_classes=3)"
      ],
      "metadata": {
        "id": "NFvQfxPjOu1D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Build LSTM Sentiment Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
        "    LSTM(128),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "v_TB4jLdOy1_",
        "outputId": "a093bd98-1398-447c-8da6-4c1ab06061a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Train the Model\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train_cat,\n",
        "    validation_data=(X_test_pad, y_test_cat),\n",
        "    epochs=51,\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPxuzTnsO4K0",
        "outputId": "53791f7a-9a3b-4e4e-a1a9-1f4bbf8adadd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6097 - loss: 0.9291 - val_accuracy: 0.6211 - val_loss: 0.9023\n",
            "Epoch 2/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6216 - loss: 0.9063 - val_accuracy: 0.6317 - val_loss: 0.9094\n",
            "Epoch 3/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6341 - loss: 0.8962 - val_accuracy: 0.6247 - val_loss: 0.9001\n",
            "Epoch 4/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6302 - loss: 0.8946 - val_accuracy: 0.6249 - val_loss: 0.9034\n",
            "Epoch 5/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6448 - loss: 0.8764 - val_accuracy: 0.6222 - val_loss: 0.9086\n",
            "Epoch 6/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6440 - loss: 0.8752 - val_accuracy: 0.6222 - val_loss: 0.9262\n",
            "Epoch 7/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6482 - loss: 0.8616 - val_accuracy: 0.6214 - val_loss: 0.9075\n",
            "Epoch 8/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6427 - loss: 0.8709 - val_accuracy: 0.6276 - val_loss: 0.9289\n",
            "Epoch 9/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6458 - loss: 0.8606 - val_accuracy: 0.6252 - val_loss: 0.9268\n",
            "Epoch 10/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6505 - loss: 0.8531 - val_accuracy: 0.6494 - val_loss: 0.9080\n",
            "Epoch 11/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.6876 - loss: 0.7647 - val_accuracy: 0.6716 - val_loss: 0.7052\n",
            "Epoch 12/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7719 - loss: 0.5321 - val_accuracy: 0.7271 - val_loss: 0.6758\n",
            "Epoch 13/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8324 - loss: 0.3914 - val_accuracy: 0.7303 - val_loss: 0.7078\n",
            "Epoch 14/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8902 - loss: 0.2753 - val_accuracy: 0.7287 - val_loss: 0.7802\n",
            "Epoch 15/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9305 - loss: 0.2041 - val_accuracy: 0.7271 - val_loss: 0.8749\n",
            "Epoch 16/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9504 - loss: 0.1464 - val_accuracy: 0.7333 - val_loss: 0.9728\n",
            "Epoch 17/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9679 - loss: 0.1072 - val_accuracy: 0.7355 - val_loss: 1.2526\n",
            "Epoch 18/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9769 - loss: 0.0787 - val_accuracy: 0.7328 - val_loss: 1.2569\n",
            "Epoch 19/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.0578 - val_accuracy: 0.7118 - val_loss: 1.2969\n",
            "Epoch 20/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0548 - val_accuracy: 0.7230 - val_loss: 1.5702\n",
            "Epoch 21/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9888 - loss: 0.0368 - val_accuracy: 0.7211 - val_loss: 1.4547\n",
            "Epoch 22/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9797 - loss: 0.0654 - val_accuracy: 0.7086 - val_loss: 1.7413\n",
            "Epoch 23/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0371 - val_accuracy: 0.7159 - val_loss: 1.7246\n",
            "Epoch 24/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0269 - val_accuracy: 0.7151 - val_loss: 1.8204\n",
            "Epoch 25/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9923 - loss: 0.0247 - val_accuracy: 0.7200 - val_loss: 2.1275\n",
            "Epoch 26/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0262 - val_accuracy: 0.7178 - val_loss: 1.8894\n",
            "Epoch 27/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0214 - val_accuracy: 0.7178 - val_loss: 2.0794\n",
            "Epoch 28/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0212 - val_accuracy: 0.7127 - val_loss: 1.9687\n",
            "Epoch 29/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.0252 - val_accuracy: 0.7140 - val_loss: 1.8135\n",
            "Epoch 30/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9848 - loss: 0.0441 - val_accuracy: 0.7110 - val_loss: 1.7694\n",
            "Epoch 31/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9930 - loss: 0.0220 - val_accuracy: 0.7165 - val_loss: 1.7762\n",
            "Epoch 32/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0193 - val_accuracy: 0.7197 - val_loss: 2.1112\n",
            "Epoch 33/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9944 - loss: 0.0165 - val_accuracy: 0.7167 - val_loss: 2.2458\n",
            "Epoch 34/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9958 - loss: 0.0134 - val_accuracy: 0.7102 - val_loss: 2.2570\n",
            "Epoch 35/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9947 - loss: 0.0136 - val_accuracy: 0.7143 - val_loss: 2.4582\n",
            "Epoch 36/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0243 - val_accuracy: 0.7148 - val_loss: 2.1932\n",
            "Epoch 37/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0275 - val_accuracy: 0.7094 - val_loss: 2.2567\n",
            "Epoch 38/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.0168 - val_accuracy: 0.7186 - val_loss: 1.9707\n",
            "Epoch 39/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9936 - loss: 0.0169 - val_accuracy: 0.7078 - val_loss: 2.5558\n",
            "Epoch 40/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9951 - loss: 0.0139 - val_accuracy: 0.7211 - val_loss: 2.6965\n",
            "Epoch 41/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9943 - loss: 0.0139 - val_accuracy: 0.7159 - val_loss: 2.4322\n",
            "Epoch 42/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0233 - val_accuracy: 0.7203 - val_loss: 2.5431\n",
            "Epoch 43/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9935 - loss: 0.0154 - val_accuracy: 0.7159 - val_loss: 2.2313\n",
            "Epoch 44/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9942 - loss: 0.0170 - val_accuracy: 0.7165 - val_loss: 2.2223\n",
            "Epoch 45/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0393 - val_accuracy: 0.7216 - val_loss: 1.9998\n",
            "Epoch 46/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0196 - val_accuracy: 0.7132 - val_loss: 2.1272\n",
            "Epoch 47/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0179 - val_accuracy: 0.7170 - val_loss: 2.3117\n",
            "Epoch 48/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0151 - val_accuracy: 0.7148 - val_loss: 2.4187\n",
            "Epoch 49/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9957 - loss: 0.0129 - val_accuracy: 0.7148 - val_loss: 2.7995\n",
            "Epoch 50/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9953 - loss: 0.0149 - val_accuracy: 0.7116 - val_loss: 2.7196\n",
            "Epoch 51/51\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.7042 - val_loss: 2.8504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Evaluate Model\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test_cat)\n",
        "print(f\"\\nTest Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfYKNrVeO95F",
        "outputId": "350c593c-8b8f-4764-ebc0-d27096b15900"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7129 - loss: 2.8102\n",
            "\n",
            "Test Accuracy: 0.7042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Prediction Function for Custom Text\n",
        "def predict_sentiment(text):\n",
        "    text_clean = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    pad = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "    pred = model.predict(pad, verbose=0)\n",
        "\n",
        "    classes = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "    sentiment = classes[np.argmax(pred)]\n",
        "    confidence = float(np.max(pred))\n",
        "\n",
        "    return {\"text\": text, \"sentiment\": sentiment, \"confidence\": confidence}\n",
        "\n",
        "# 🔹 Interactive Comment Input\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter a comment (or type 'exit' to quit): \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    result = predict_sentiment(user_input)\n",
        "    print(f\"Comment: {result['text']}\")\n",
        "    print(f\"Predicted Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMr5Zxd4PvTK",
        "outputId": "11310bc2-ea40-4611-97f0-e864986bdad0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter a comment (or type 'exit' to quit): sonu\n",
            "Comment: sonu\n",
            "Predicted Sentiment: Neutral (Confidence: 0.81)\n",
            "\n",
            "Enter a comment (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Test with Custom Inputs\n",
        "print(predict_sentiment(\"I love this video! It's amazing.\"))\n",
        "print(predict_sentiment(\"This is the worst video ever.\"))\n",
        "print(predict_sentiment(\"The video is okay, not too bad but not great either.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6NegvhoP00h",
        "outputId": "67b4b03e-9458-48ea-a7c3-fb8057d79134"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \"I love this video! It's amazing.\", 'sentiment': 'Positive', 'confidence': 0.9999997615814209}\n",
            "{'text': 'This is the worst video ever.', 'sentiment': 'Negative', 'confidence': 0.9999986886978149}\n",
            "{'text': 'The video is okay, not too bad but not great either.', 'sentiment': 'Negative', 'confidence': 0.965998113155365}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Save Model and Tokenizer for Django\n",
        "model_dir = 'sentiment_model'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Save model\n",
        "model_path = os.path.join(model_dir, 'sentiment_lstm.h5')\n",
        "save_model(model, model_path)\n",
        "print(f\"Saved model to {model_path}\")\n",
        "\n",
        "# Save tokenizer\n",
        "import pickle\n",
        "tokenizer_path = os.path.join(model_dir, 'tokenizer.pkl')\n",
        "with open(tokenizer_path, 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "print(f\"Saved tokenizer to {tokenizer_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6BqLZnlP6Vr",
        "outputId": "83de8b36-9d0c-4342-fa38-c0508f6d2173"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to sentiment_model/sentiment_lstm.h5\n",
            "Saved tokenizer to sentiment_model/tokenizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5h3dTfL3VlCm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}